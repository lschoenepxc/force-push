{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start: Analysiere Daten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import initial_data.csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from feasibility import is_feasible\n",
    "\n",
    "# import data from csv file\n",
    "def import_data():\n",
    "    data = pd.read_csv('initial_data.csv')\n",
    "    return data\n",
    "\n",
    "data = import_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Engine speed' 'Engine load' 'Railpressure' 'Air supply' 'Crank angle'\n",
      " 'Intake pressure' 'Back pressure' 'Intake temperature' 'NOx' 'PM 1' 'CO2'\n",
      " 'PM 2' 'Pressure cylinder']\n",
      "['Engine speed' 'Engine load' 'Railpressure' 'Air supply' 'Crank angle'\n",
      " 'Intake pressure' 'Back pressure' 'Intake temperature']\n",
      "['NOx' 'PM 1' 'CO2' 'PM 2' 'Pressure cylinder']\n"
     ]
    }
   ],
   "source": [
    "# put column names into a list\n",
    "column_names = data.columns.values\n",
    "print(column_names)\n",
    "inputs = column_names[0:8]\n",
    "print(inputs)\n",
    "outputs = column_names[8:13]\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_input_data(row):\n",
    "    x1, x2, x3, x4, x5, x6, x7, x8 = data.iloc[row, 0], data.iloc[row, 1], data.iloc[row, 2], data.iloc[row, 3], data.iloc[row, 4], data.iloc[row, 5], data.iloc[row, 6], data.iloc[row, 7]\n",
    "    return x1, x2, x3, x4, x5, x6, x7, x8\n",
    "\n",
    "def get_output_data(row):\n",
    "    x1, x2, x3, x4, x5 = data.iloc[row, 8], data.iloc[row, 9], data.iloc[row, 10], data.iloc[row, 11], data.iloc[row, 12]\n",
    "    return x1, x2, x3, x4, x5\n",
    "\n",
    "def get_critical_output_data(i):\n",
    "    x1, x2, x3 = data.iloc[i, 9], data.iloc[i, 11], data.iloc[i, 12]\n",
    "    return x1, x2, x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show if data row is feasible via the first 8 columns and the function is_feasible\n",
    "feasible = []\n",
    "for i in range(len(data)):\n",
    "    x1, x2, x3, x4, x5, x6, x7, x8 = get_input_data(i)\n",
    "    # print(x1, x2, x3, x4, x5, x6, x7, x8)\n",
    "    feasible.append(is_feasible(x1, x2, x3, x4, x5, x6, x7, x8))\n",
    "data['feasible'] = feasible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if outputs are in safe range\n",
    "# PM 1 < 6, PM 2 < 16, Pressure cylinder < 160\n",
    "safe = []\n",
    "for i in range(len(data)):\n",
    "    x9, x10, x11 = get_critical_output_data(i)\n",
    "    if x9 < 6 and x10 < 16 and x11 < 160:\n",
    "        safe.append(True)\n",
    "    else:\n",
    "        safe.append(False)\n",
    "data['safe'] = safe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Engine speed  Engine load  Railpressure  Air supply  Crank angle  \\\n",
      "70        1800.0        35.66        1521.7    310.5600         5.69   \n",
      "89        2000.0       139.54        2500.3   1008.3008         3.66   \n",
      "\n",
      "    Intake pressure  Back pressure  Intake temperature         NOx      PM 1  \\\n",
      "70           1123.5         1236.1                60.9   66.869420  4.095885   \n",
      "89           3129.9         3329.4                79.7  328.147428  4.017909   \n",
      "\n",
      "           CO2       PM 2  Pressure cylinder  feasible   safe  \n",
      "70   36.291467  16.283255          60.497930      True  False  \n",
      "89  163.080520   4.692198         160.047375      True  False  \n"
     ]
    }
   ],
   "source": [
    "# show unsafe data (safe = False)\n",
    "unsafe_data = data[data['safe'] == False]\n",
    "print(unsafe_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict when to get safe data and when to get unsafe data\n",
    "# PM 1 < 6, PM 2 < 16, Pressure cylinder < 160"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import re\n",
    "\n",
    "def read_csv_data_init(file_path):\n",
    "    data = []\n",
    "    with open(file_path, 'r') as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        # Überschriftszeile überspringen\n",
    "        next(reader, None)\n",
    "        for row in reader:\n",
    "            data.append(row)\n",
    "    return data\n",
    "\n",
    "def read_csv_data_querry(file_path):\n",
    "    # Initialisiere eine leere Liste, um die bereinigten Daten zu speichern\n",
    "    cleaned_data = []\n",
    "\n",
    "    # Lese die CSV-Datei\n",
    "    with open(file_path, 'r') as csvfile:\n",
    "        reader = csv.reader(csvfile, delimiter=';')  # Annahme: Semikolon als Trennzeichen\n",
    "        for row in reader:\n",
    "            # Verbinde die Zeilenelemente mit einem Komma, um das Trennzeichen zu vereinheitlichen\n",
    "            unified_row = ','.join(row)\n",
    "            # Ersetze mehrere aufeinander folgende Kommas durch ein einzelnes Komma\n",
    "            unified_row = re.sub(r',+', ',', unified_row)\n",
    "            # Teile die vereinheitlichte Zeile nach dem Komma auf\n",
    "            split_row = unified_row.split(',')\n",
    "            # Entferne die ersten zwei Parameter\n",
    "            cleaned_row = split_row[1:]\n",
    "            # Füge die bereinigte Zeile der Liste hinzu\n",
    "            cleaned_data.append(cleaned_row)\n",
    "    return cleaned_data[1:]\n",
    "    #return cleaned_data\n",
    "\n",
    "\n",
    "# Beispiel: Daten aus \"input.csv\" einlesen\n",
    "input_file_path_querry = \"querys_ForcePush (1).csv\"\n",
    "input_file_path_init = \"initial_data.csv\"\n",
    "\n",
    "querryData = read_csv_data_querry(input_file_path_querry)\n",
    "\n",
    "initData = read_csv_data_init(input_file_path_init)\n",
    "\n",
    "\n",
    "#data = initData + querryData\n",
    "data = initData\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_x = [row[:8] for row in data]\n",
    "i_x = pd.DataFrame(i_x)\n",
    "i_x = i_x.astype(float)\n",
    "\n",
    "i_y = [row[-5:] for row in data]\n",
    "i_y = pd.DataFrame(i_y)\n",
    "i_y = i_y.astype(float)\n",
    "\n",
    "init_var = i_y.std()\n",
    "init_mean = i_y.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = read_csv_data_init(\"submission.csv\")\n",
    "\n",
    "s_x = [row[:8] for row in data]\n",
    "s_x = pd.DataFrame(s_x)\n",
    "s_x = s_x.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV \n",
    "from sklearn.ensemble import RandomForestRegressor \n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error\n",
    "\n",
    "x = i_x\n",
    "y = i_y\n",
    "\n",
    "# Daten in Trainings- und Testdatensatz aufteilen \n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Hyperparameter-Tuning mit Grid-Suche für Random Forest Regressor \n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [3, 5, 7, 10, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'] \n",
    "}\n",
    "\n",
    "rf_model = RandomForestRegressor(random_state=42)\n",
    "\n",
    "grid_search = GridSearchCV(estimator=rf_model, param_grid=param_grid, cv=5, scoring='neg_mean_squared_error') \n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "print(f\"Beste Hyperparameter: {best_params}\")\n",
    "\n",
    "# Modell mit den besten Hyperparametern trainieren \n",
    "best_rf_model = RandomForestRegressor(**best_params, random_state=42) \n",
    "best_rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Vorhersagen machen\n",
    "y_pred_rf = best_rf_model.predict(X_test)\n",
    "\n",
    "# Modellbewertung für Random Forest\n",
    "mse_rf = mean_squared_error(np.array(y_test), y_pred_rf) \n",
    "print(f\"Mean Squared Error (Random Forest): {mse_rf}\") \n",
    "mape_rf = mean_absolute_percentage_error(np.array(y_test), y_pred_rf) \n",
    "print(f\"Mean Absolute Percentage Error (Random Forest): {mape_rf}\")\n",
    "\n",
    "# MAPE für jeden Ausgabeparameter nach Random Forest \n",
    "mape_per_output_rf = mean_absolute_percentage_error(np.array(y_test), y_pred_rf, multioutput='raw_values') \n",
    "for i, mape in enumerate(mape_per_output_rf):\n",
    "    print(f\"MAPE für Ausgabeparameter {i+1} (Random Forest): {mape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init var: 0    134.135904\n",
      "1      1.305993\n",
      "2     40.338013\n",
      "3      3.059437\n",
      "4     28.450298\n",
      "dtype: float64\n",
      "init mean: 0    170.290383\n",
      "1      1.901737\n",
      "2     59.829099\n",
      "3      5.450735\n",
      "4     82.803179\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "Quotienten model var: 0    0.948146\n",
      "1    0.800914\n",
      "2    0.813154\n",
      "3    0.893079\n",
      "4    0.832030\n",
      "dtype: float64\n",
      "Quotienten model mean: 0    0.972940\n",
      "1    0.741922\n",
      "2    0.823625\n",
      "3    0.857070\n",
      "4    0.928192\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "Quotienten model var: 0    0.948146\n",
      "1    0.800914\n",
      "2    0.813154\n",
      "3    0.893079\n",
      "4    0.832030\n",
      "dtype: float64\n",
      "Quotienten model mean: 0    0.972940\n",
      "1    0.741922\n",
      "2    0.823625\n",
      "3    0.857070\n",
      "4    0.928192\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "Quotienten model var: 0    0.858981\n",
      "1    0.578753\n",
      "2    0.725920\n",
      "3    0.474298\n",
      "4    0.755278\n",
      "dtype: float64\n",
      "Quotienten model mean: 0    0.962029\n",
      "1    0.935452\n",
      "2    0.937518\n",
      "3    0.945419\n",
      "4    0.960312\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error\n",
    "\n",
    "\n",
    "# Daten in Trainings- und Testdatensatz aufteilen\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# y_test = np.array(y_test)\n",
    "\n",
    "# Decision Tree Regressor Modell erstellen und trainieren\n",
    "model = DecisionTreeRegressor()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Vorhersagen machen\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Modellbewertung ohne Pruning\n",
    "\n",
    "\n",
    "# Pruning mit Grid-Suche für Hyperparameter-Optimierung\n",
    "param_grid = {\n",
    "    'max_depth': [1, 3, 5, 7, 10, 13],\n",
    "    'min_samples_split': [2, 5, 10, 15],\n",
    "    'min_samples_leaf': [1, 2, 4, 8],\n",
    "    'max_features': ['sqrt', 'log2']\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "# Modell mit den besten Hyperparametern trainieren\n",
    "best_model = DecisionTreeRegressor(**best_params)\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "# Vorhersagen machen mit dem geprüften Modell\n",
    "y_pred_pruned = best_model.predict(X_test)\n",
    "\n",
    "# Modellbewertung nach Pruning\n",
    "\n",
    "\n",
    "# Random Forest Regressor Modell erstellen und trainieren\n",
    "rf_model = RandomForestRegressor(n_estimators=100)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Vorhersagen machen mit dem Random Forest Modell\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "# Modellbewertung für Random Forest\n",
    "\n",
    "\n",
    "print(f\"init var: {init_var}\")\n",
    "print(f\"init mean: {init_mean}\")\n",
    "print(\"\\n\")\n",
    "\n",
    "model_y = model.predict(s_x)\n",
    "model_y = pd.DataFrame(model_y)\n",
    "model_y = model_y.astype(float)\n",
    "print(f\"Quotienten model var: {(model_y.std())/init_var}\")\n",
    "print(f\"Quotienten model mean: {(model_y.mean())/init_mean}\")\n",
    "print(\"\\n\")\n",
    "\n",
    "best_model = model.predict(s_x)\n",
    "best_model = pd.DataFrame(best_model)\n",
    "best_model = best_model.astype(float)\n",
    "print(f\"Quotienten model var: {(best_model.std())/init_var}\")\n",
    "print(f\"Quotienten model mean: {best_model.mean()/init_mean}\")\n",
    "print(\"\\n\")\n",
    "\n",
    "rf_model = rf_model.predict(s_x)\n",
    "rf_model = pd.DataFrame(rf_model)\n",
    "rf_model = rf_model.astype(float)\n",
    "print(f\"Quotienten model var: {(rf_model.std())/init_var}\")\n",
    "print(f\"Quotienten model mean: {(rf_model.mean())/init_mean}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (vor Pruning): 256.9242345774802\n",
      "Mean Squared Error für Ausgabeparameter 1: 1189.6459491152416 : 0.066119208895669\n",
      "Mean Squared Error für Ausgabeparameter 2: 0.4802440599498167 : 0.2815661204604644\n",
      "Mean Squared Error für Ausgabeparameter 3: 41.834136507145686 : 0.025709983474385\n",
      "Mean Squared Error für Ausgabeparameter 4: 9.982944895931851 : 1.0665360067472907\n",
      "Mean Squared Error für Ausgabeparameter 5: 42.6778983091318 : 0.05272655238017956\n",
      "Mean Absolut Percantage Error für Ausgabeparameter 1: 18.797339200283066\n",
      "Mean Absolut Percantage Error für Ausgabeparameter 2: 30.69505308888721\n",
      "Mean Absolut Percantage Error für Ausgabeparameter 3: 24.01394207237853\n",
      "Mean Absolut Percantage Error für Ausgabeparameter 4: 36.62418018477196\n",
      "Mean Absolut Percantage Error für Ausgabeparameter 5: 6.80344932511892\n",
      "Mean Squared Error (nach Pruning): 816.3694253411219\n",
      "Mean Squared Error für Ausgabeparameter 1: 3889.4902549236967 : 0.21617357572160875\n",
      "Mean Squared Error für Ausgabeparameter 2: 1.0444263603903097 : 0.6123450614516125\n",
      "Mean Squared Error für Ausgabeparameter 3: 129.8063666355292 : 0.07977503110406901\n",
      "Mean Squared Error für Ausgabeparameter 4: 16.64154245839408 : 1.7779126725345271\n",
      "Mean Squared Error für Ausgabeparameter 5: 44.86453632759848 : 0.05542804164242156\n",
      "Mean Absolut Percantage Error für Ausgabeparameter 1: 36.67071574855784\n",
      "Mean Absolut Percantage Error für Ausgabeparameter 2: 120.75553010253488\n",
      "Mean Absolut Percantage Error für Ausgabeparameter 3: 48.80098001317174\n",
      "Mean Absolut Percantage Error für Ausgabeparameter 4: 106.87613815227226\n",
      "Mean Absolut Percantage Error für Ausgabeparameter 5: 8.793315300787693\n",
      "Mean Squared Error (Random Forest): 62.62173201714937\n",
      "Mean Squared Error für Ausgabeparameter 1: 267.4099215583748 : 0.014862348312489301\n",
      "Mean Squared Error für Ausgabeparameter 2: 0.4790631746630033 : 0.28087376980660805\n",
      "Mean Squared Error für Ausgabeparameter 3: 18.388187961801318 : 0.011300819094020143\n",
      "Mean Squared Error für Ausgabeparameter 4: 9.31269432946645 : 0.9949292444010991\n",
      "Mean Squared Error für Ausgabeparameter 5: 17.51879306144134 : 0.021643651552400077\n",
      "Mean Absolut Percantage Error für Ausgabeparameter 1: 16.930976044121067\n",
      "Mean Absolut Percantage Error für Ausgabeparameter 2: 60.53373076778341\n",
      "Mean Absolut Percantage Error für Ausgabeparameter 3: 29.8659598490013\n",
      "Mean Absolut Percantage Error für Ausgabeparameter 4: 53.43844932992477\n",
      "Mean Absolut Percantage Error für Ausgabeparameter 5: 5.659823840754804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\CM3EXN\\dev\\force-push\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:540: FitFailedWarning: \n",
      "480 fits failed out of a total of 1440.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "480 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\CM3EXN\\dev\\force-push\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\CM3EXN\\dev\\force-push\\myenv\\lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\CM3EXN\\dev\\force-push\\myenv\\lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\CM3EXN\\dev\\force-push\\myenv\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of DecisionTreeRegressor must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\CM3EXN\\dev\\force-push\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1052: UserWarning: One or more of the test scores are non-finite: [           nan            nan            nan            nan\n",
      "            nan            nan            nan            nan\n",
      "            nan            nan            nan            nan\n",
      "            nan            nan            nan            nan\n",
      " -3420.48794918 -2108.92746653 -2643.73160996 -3310.4526089\n",
      " -2764.01155696 -2616.77251821 -3045.94039913 -3046.85384068\n",
      " -2976.73517841 -3163.32043534 -2888.14522868 -3239.6804932\n",
      " -2986.6734998  -2925.32276647 -2411.42502277 -2981.0205871\n",
      " -2797.37887825 -3037.74517371 -2643.87723908 -2300.70414957\n",
      " -2207.40601945 -3695.44987272 -2484.94267765 -2538.38312083\n",
      " -2294.56714552 -2832.61892648 -3447.90265888 -2570.43787317\n",
      " -2441.6528469  -2494.24155047 -2105.30592718 -2511.75229082\n",
      "            nan            nan            nan            nan\n",
      "            nan            nan            nan            nan\n",
      "            nan            nan            nan            nan\n",
      "            nan            nan            nan            nan\n",
      " -1888.07786279 -2050.15210811 -1801.75352607 -1585.21469345\n",
      " -2505.96449852 -1301.42224192 -1719.68067492 -2043.68990969\n",
      " -1810.38145364 -1456.88645354 -2063.76392792 -1890.66462531\n",
      " -1957.8045345  -1922.90604449 -1449.45782979 -1953.70557923\n",
      " -1403.61426452 -1965.32177468 -1432.69658909 -1272.55412331\n",
      " -1338.95489519 -1064.8039835  -1414.83639728 -1661.31564964\n",
      " -1491.19140668 -1273.69151139 -1215.85464695 -1322.22643537\n",
      " -1300.5113583  -1598.20638665 -1432.18367764 -1458.78278633\n",
      "            nan            nan            nan            nan\n",
      "            nan            nan            nan            nan\n",
      "            nan            nan            nan            nan\n",
      "            nan            nan            nan            nan\n",
      " -1583.9774735  -1501.6730506  -1179.3043456  -1780.71733717\n",
      " -1540.30902836 -1111.90338761 -1575.1357831  -1397.03398334\n",
      " -1220.81486687 -1808.11946183 -1632.89871391 -1608.99471834\n",
      " -1225.6738068  -1596.05611417 -1608.61616178 -2136.27641433\n",
      " -1468.17451731 -1076.4548866  -1323.40316076 -2115.8941404\n",
      "  -998.87331761  -926.37954884 -1809.58671624 -1918.08831531\n",
      " -1282.50824037 -1519.82643823 -1107.94717873 -1232.4059244\n",
      " -1802.05772119 -1390.48889837 -1514.14417748 -1584.67098089\n",
      "            nan            nan            nan            nan\n",
      "            nan            nan            nan            nan\n",
      "            nan            nan            nan            nan\n",
      "            nan            nan            nan            nan\n",
      "  -942.01079037 -1473.09321056 -1749.9628853  -1507.71114082\n",
      " -1036.47897115 -1935.83720762 -1309.63378673 -1704.83177975\n",
      " -1668.33869465 -1428.58494449 -1292.77831694 -1401.54161439\n",
      " -1372.94076344 -1499.08555891 -1475.02242734 -1539.03244116\n",
      " -1506.43543283 -1234.50820761 -1305.63589093 -1381.70035056\n",
      " -1380.7167475  -1748.31452357 -1559.68538667 -1570.41434591\n",
      " -1218.76565856 -1080.87460348 -1275.91970728 -1743.76233257\n",
      " -1471.39953611 -1309.45104804 -1374.18408755 -1453.95108946\n",
      "            nan            nan            nan            nan\n",
      "            nan            nan            nan            nan\n",
      "            nan            nan            nan            nan\n",
      "            nan            nan            nan            nan\n",
      " -1434.53194333 -1241.51218051 -1790.80847193 -1855.3280694\n",
      " -1315.96179368 -1454.54145629 -1758.93353642 -1317.5594155\n",
      " -1097.60348247 -1586.70111761 -1236.35014164 -2038.37231091\n",
      " -1322.48684195 -1575.89881566 -1244.50346978 -1613.65119609\n",
      "  -998.78866887 -1165.92794544  -913.69620543 -1537.66474455\n",
      " -2058.61341615 -1284.27061328 -1504.52830726 -1322.31449415\n",
      " -1346.65716673 -1004.74856068 -1209.62349686 -1489.21604081\n",
      " -1188.94913268 -1569.55950659 -1290.84034821 -1831.1996986\n",
      "            nan            nan            nan            nan\n",
      "            nan            nan            nan            nan\n",
      "            nan            nan            nan            nan\n",
      "            nan            nan            nan            nan\n",
      " -1086.56618783 -1531.83053917 -1832.07836379 -1423.32839396\n",
      " -1189.97718622 -1120.124674   -1149.71255967 -1367.05809704\n",
      " -1631.7074088  -1538.85531706 -2213.3804692  -1744.08839673\n",
      " -1751.67280895 -1617.2164958  -1325.60769726 -1970.09677199\n",
      " -1289.98979228  -988.13148273 -1202.1113183  -1279.15923407\n",
      " -1036.79118194  -985.32576705 -1207.17240087 -1189.21388439\n",
      " -1175.17826803 -1444.56048003 -1251.14049725 -1333.82331997\n",
      " -1489.03453559 -1475.35513121 -1164.37904881 -1406.70942902]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error\n",
    "\n",
    "\n",
    "# Daten in Trainings- und Testdatensatz aufteilen\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# y_test = np.array(y_test)\n",
    "\n",
    "# Decision Tree Regressor Modell erstellen und trainieren\n",
    "model = DecisionTreeRegressor()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Vorhersagen machen\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Modellbewertung ohne Pruning\n",
    "mse_before_pruning = mean_squared_error(y_test, y_pred)\n",
    "print(f\"Mean Squared Error (vor Pruning): {mse_before_pruning}\")\n",
    "mape_before_pruning = mean_absolute_percentage_error(y_test, y_pred=y_pred, multioutput='raw_values')*100\n",
    "\n",
    "mse_per_output = mean_squared_error(y_test, y_pred, multioutput='raw_values')\n",
    "for i, mse in enumerate(mse_per_output):\n",
    "    print(f\"Mean Squared Error für Ausgabeparameter {i+1}: {mse} : {mse/var[i]}\")\n",
    "for i, mse in enumerate(mape_before_pruning):\n",
    "    print(f\"Mean Absolut Percantage Error für Ausgabeparameter {i+1}: {mse}\")\n",
    "\n",
    "# Pruning mit Grid-Suche für Hyperparameter-Optimierung\n",
    "param_grid = {\n",
    "    'max_depth': [1, 3, 5, 7, 10, 13],\n",
    "    'min_samples_split': [2, 5, 10, 15],\n",
    "    'min_samples_leaf': [1, 2, 4, 8],\n",
    "    'max_features': ['auto', 'sqrt', 'log2']\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "# Modell mit den besten Hyperparametern trainieren\n",
    "best_model = DecisionTreeRegressor(**best_params)\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "# Vorhersagen machen mit dem geprüften Modell\n",
    "y_pred_pruned = best_model.predict(X_test)\n",
    "\n",
    "# Modellbewertung nach Pruning\n",
    "mse_after_pruning = mean_squared_error(y_test, y_pred_pruned)\n",
    "print(f\"Mean Squared Error (nach Pruning): {mse_after_pruning}\")\n",
    "mape_after_pruning = mean_absolute_percentage_error(y_test, y_pred=y_pred_pruned, multioutput='raw_values')*100\n",
    "\n",
    "mse_per_output = mean_squared_error(y_test, y_pred_pruned, multioutput='raw_values')\n",
    "for i, mse in enumerate(mse_per_output):\n",
    "    print(f\"Mean Squared Error für Ausgabeparameter {i+1}: {mse} : {mse/var[i]}\")\n",
    "for i, mse in enumerate(mape_after_pruning):\n",
    "    print(f\"Mean Absolut Percantage Error für Ausgabeparameter {i+1}: {mse}\")\n",
    "\n",
    "# Random Forest Regressor Modell erstellen und trainieren\n",
    "rf_model = RandomForestRegressor(n_estimators=100)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Vorhersagen machen mit dem Random Forest Modell\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "# Modellbewertung für Random Forest\n",
    "mse_rf = mean_squared_error(y_test, y_pred_rf)\n",
    "print(f\"Mean Squared Error (Random Forest): {mse_rf}\")\n",
    "mape_rf = mean_absolute_percentage_error(y_test, y_pred=y_pred_rf, multioutput='raw_values')*100\n",
    "\n",
    "mse_per_output = mean_squared_error(y_test, y_pred_rf, multioutput='raw_values')\n",
    "for i, mse in enumerate(mse_per_output):\n",
    "    print(f\"Mean Squared Error für Ausgabeparameter {i+1}: {mse} : {mse/var[i]}\")\n",
    "for i, mse in enumerate(mape_rf):\n",
    "    print(f\"Mean Absolut Percantage Error für Ausgabeparameter {i+1}: {mse}\")\n",
    "\n",
    "\n",
    "# new_Input = [[1216.320277750492, 169.48516483418643, 1501.1897808736858, 555.3636147531786, 6.218004648108035, 2903.9827555595525, 2098.829896093796, 56.01301888900216]]\n",
    "# predict_output = best_model.predict(new_Input)\n",
    "# print(f\"Ewarteter Ausgabewert für neue Eingabe (nach Pruning): {predict_output}\")\n",
    "\n",
    "# predict_output = rf_model.predict(new_Input)\n",
    "# print(f\"Ewarteter Ausgabewert für neue Eingabe (Random Forest): {predict_output}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
