{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start: Analysiere Daten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "137\n",
      "137\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "def read_csv_file(file_path):\n",
    "    # Initialisiere eine leere Liste, um die bereinigten Daten zu speichern\n",
    "    cleaned_data = []\n",
    "\n",
    "    # Lese die CSV-Datei\n",
    "    with open(file_path, 'r') as csvfile:\n",
    "        reader = csv.reader(csvfile, delimiter=';')  # Annahme: Semikolon als Trennzeichen\n",
    "        for row in reader:\n",
    "            # Verbinde die Zeilenelemente mit einem Komma, um das Trennzeichen zu vereinheitlichen\n",
    "            unified_row = ','.join(row)\n",
    "            # Ersetze mehrere aufeinander folgende Kommas durch ein einzelnes Komma\n",
    "            unified_row = re.sub(r',+', ',', unified_row)\n",
    "            # Teile die vereinheitlichte Zeile nach dem Komma auf\n",
    "            split_row = unified_row.split(',')\n",
    "            # Entferne die ersten zwei Parameter\n",
    "            cleaned_row = split_row[1:]\n",
    "            # Füge die bereinigte Zeile der Liste hinzu\n",
    "            cleaned_data.append(cleaned_row)\n",
    "\n",
    "    return cleaned_data\n",
    "\n",
    "# Beispiel: Daten aus \"input.csv\" einlesen\n",
    "\n",
    "data = pd.read_csv(\"initial_data.csv\")\n",
    "cleaned_data = read_csv_file(\"querys_ForcePush (3).csv\")\n",
    "df_queried = pd.DataFrame(cleaned_data[1:], columns=cleaned_data[0])\n",
    "def add_data(data, queried_data):\n",
    "    data = pd.concat([data, queried_data.iloc[:, :13]], axis=0)\n",
    "    return data\n",
    "\n",
    "\n",
    "df_queried_2 = df_queried[df_queried['costs'] == str(1)]\n",
    "data = add_data(data, df_queried_2)\n",
    "data = data.reset_index().astype('Float32')\n",
    "# print(len(data))\n",
    "\n",
    "\n",
    "#print(data)\n",
    "#print(data.keys())\n",
    "\n",
    "x = data[['Engine speed', 'Engine load', 'Railpressure', 'Air supply', 'Crank angle', 'Intake pressure', 'Back pressure', 'Intake temperature']]\n",
    "y = data[['NOx', 'PM 1', 'CO2', 'Pressure cylinder']]\n",
    "\n",
    "print(len(x))\n",
    "print(len(y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beste Hyperparameter: {'bootstrap': False, 'max_depth': 7, 'max_features': 'log2', 'max_leaf_nodes': 30, 'min_samples_leaf': 2, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100}\n",
      "Mean Absolute Percentage Error (Random Forest): 65.28433345541711\n",
      "MAPE für Ausgabeparameter 1 (Random Forest): 66.00588699755795\n",
      "MAPE für Ausgabeparameter 2 (Random Forest): 29.760751682022217\n",
      "MAPE für Ausgabeparameter 3 (Random Forest): 73.09039332494481\n",
      "MAPE für Ausgabeparameter 4 (Random Forest): 92.28030181714348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\CM3EXN\\dev\\force-push\\myenv\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SelectFromModel was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\CM3EXN\\dev\\force-push\\myenv\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SelectFromModel was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV \n",
    "from sklearn.ensemble import RandomForestRegressor \n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "\n",
    "# Daten in Trainings- und Testdatensatz aufteilen \n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Hyperparameter-Tuning mit Grid-Suche für Random Forest Regressor \n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 150],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'min_samples_split': [2, 3, 4],\n",
    "    'min_samples_leaf': [1, 2],\n",
    "    'max_features': ['log2','sqrt'],\n",
    "    'bootstrap': [True, False],\n",
    "    # 'criterion': ['mse', 'mae'],\n",
    "}\n",
    "\n",
    "rf_model = RandomForestRegressor(random_state=42)\n",
    "\n",
    "grid_search = GridSearchCV(estimator=rf_model, param_grid=param_grid, cv=5, scoring='neg_mean_squared_error') \n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "print(f\"Beste Hyperparameter: {best_params}\")\n",
    "\n",
    "# Modell trainieren und bewerten\n",
    "best_rf_model = RandomForestRegressor(**best_params, random_state=42) \n",
    "best_rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Vorhersagen machen mit dem Random Forest Modell\n",
    "y_pred_rf = best_rf_model.predict(X_test)\n",
    "\n",
    "# Feature Selection basierend auf den RF Modell\n",
    "selector = SelectFromModel(best_rf_model, threshold='mean', prefit=True)\n",
    "\n",
    "X_train_selected = selector.transform(X_train)\n",
    "X_test_selected = selector.transform(X_test)\n",
    "\n",
    "# Modell trainieren erneut trainieren und bewerten \n",
    "best_rf_model.fit(X_train_selected, y_train)\n",
    "y_pred_rf = best_rf_model.predict(X_test_selected)\n",
    "\n",
    "# Modellbewertung für Random Forest\n",
    "# mse_rf = mean_squared_error(y_test, y_pred_rf) \n",
    "# print(f\"Mean Squared Error (Random Forest): {mse_rf}\") \n",
    "mape_rf = mean_absolute_percentage_error(y_test, y_pred_rf) \n",
    "print(f\"Mean Absolute Percentage Error (Random Forest): {100-mape_rf*100}\")\n",
    "\n",
    "# MAPE für jeden Ausgabeparameter nach Random Forest \n",
    "mape_per_output_rf = mean_absolute_percentage_error(y_test, y_pred_rf, multioutput='raw_values') \n",
    "for i, mape in enumerate(mape_per_output_rf):\n",
    "    print(f\"MAPE für Ausgabeparameter {i+1} (Random Forest): {100-mape*100}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
