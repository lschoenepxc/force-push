{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "# Beispielhafte Daten\n",
    "# X = np.random.rand(100, 13)\n",
    "# y = np.random.rand(100, 5)\n",
    "\n",
    "# Deine echten Daten hier laden\n",
    "X = ... # Dein Input-Datensatz (100, 13)\n",
    "y = ... # Dein Output-Datensatz (100, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import re\n",
    "\n",
    "def read_csv_file(file_path):\n",
    "    # Initialisiere eine leere Liste, um die bereinigten Daten zu speichern\n",
    "    cleaned_data = []\n",
    "\n",
    "    # Lese die CSV-Datei\n",
    "    with open(file_path, 'r') as csvfile:\n",
    "        reader = csv.reader(csvfile, delimiter=';')  # Annahme: Semikolon als Trennzeichen\n",
    "        for row in reader:\n",
    "            # Verbinde die Zeilenelemente mit einem Komma, um das Trennzeichen zu vereinheitlichen\n",
    "            unified_row = ','.join(row)\n",
    "            # Ersetze mehrere aufeinander folgende Kommas durch ein einzelnes Komma\n",
    "            unified_row = re.sub(r',+', ',', unified_row)\n",
    "            # Teile die vereinheitlichte Zeile nach dem Komma auf\n",
    "            split_row = unified_row.split(',')\n",
    "            # Entferne die ersten zwei Parameter\n",
    "            cleaned_row = split_row[1:]\n",
    "            # FÃ¼ge die bereinigte Zeile der Liste hinzu\n",
    "            cleaned_data.append(cleaned_row)\n",
    "\n",
    "    return cleaned_data\n",
    "\n",
    "# Beispiel: Daten aus \"input.csv\" einlesen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     index  Engine speed  Engine load  Railpressure  Air supply  Crank angle  \\\n",
      "0      0.0         700.0         7.33    500.899994   78.375298         1.91   \n",
      "1      1.0         700.0        25.85    577.599976  118.067299         0.94   \n",
      "2      2.0         700.0    46.669998    615.799988  144.355698         2.86   \n",
      "3      3.0         700.0    69.550003    778.299988  174.177902         2.22   \n",
      "4      4.0         700.0    94.330002    900.099976  213.314804        -1.72   \n",
      "..     ...           ...          ...           ...         ...          ...   \n",
      "108    8.0   2183.257812    47.490673   1444.360107  650.760376     4.574534   \n",
      "109    9.0   1896.591187    97.303398   1351.508545  827.040039    -3.222039   \n",
      "110   10.0   1199.474487   101.517929   1868.645874  393.788116    -0.035194   \n",
      "111   11.0     903.48175    10.912282    960.143188  602.400879     4.090658   \n",
      "112   12.0    989.338928    81.168571    798.997742  610.851624     4.238798   \n",
      "\n",
      "     Intake pressure  Back pressure  Intake temperature         NOx      PM 1  \\\n",
      "0              967.5    1027.300049                65.5   17.977839  0.151139   \n",
      "1        1017.599976    1063.800049           53.400002   30.613787  0.421432   \n",
      "2        1086.699951    1156.199951           47.900002  109.199806  0.767395   \n",
      "3        1171.099976    1215.099976           42.700001  186.406723  0.658505   \n",
      "4        1313.300049    1305.900024           38.299999  315.430176  0.773289   \n",
      "..               ...            ...                 ...         ...       ...   \n",
      "108      1214.924438    2534.904785           63.454926  267.957947  1.561381   \n",
      "109      1957.858154    2360.668213           61.206924  655.742188  3.415683   \n",
      "110      2519.380859    1297.593384           53.867203  318.380676  8.514029   \n",
      "111      2214.485596    1118.469849           65.710732   97.881203  0.366846   \n",
      "112      2893.275635    3159.828369           46.599705  790.772034  0.453512   \n",
      "\n",
      "            CO2       PM 2  Pressure cylinder  \n",
      "0      2.891628   1.690336          44.946301  \n",
      "1     10.976312   4.617809          55.885777  \n",
      "2     18.844496   5.139177          73.029762  \n",
      "3     27.739765   4.104144          86.322105  \n",
      "4     39.269863   4.298426           93.84214  \n",
      "..          ...        ...                ...  \n",
      "108   48.390953   0.092351          68.638382  \n",
      "109  108.400719  42.976513         104.524902  \n",
      "110   83.169342   0.008595         114.401657  \n",
      "111    9.534796   1.038233         108.758553  \n",
      "112   42.087067   0.912289         161.766251  \n",
      "\n",
      "[113 rows x 14 columns]\n",
      "NOx                   774.920654\n",
      "PM 1                   13.661119\n",
      "CO2                   160.188889\n",
      "PM 2                 5505.038574\n",
      "Pressure cylinder     117.810837\n",
      "dtype: Float32\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"initial_data.csv\")\n",
    "cleaned_data = read_csv_file(\"querys_ForcePush.csv\")\n",
    "df_queried = pd.DataFrame(cleaned_data[1:], columns=cleaned_data[0])\n",
    "def add_data(data, queried_data):\n",
    "    # add queried data (without cost) to initial data\n",
    "    data = pd.concat([data, queried_data.iloc[:, :13]], axis=0)\n",
    "\n",
    "    # data = data.append(queried_data, ignore_index=True)\n",
    "    return data\n",
    "\n",
    "data = add_data(data, df_queried)\n",
    "data = data.reset_index().astype('Float32')\n",
    "\n",
    "print(data)\n",
    "\n",
    "#print(data)\n",
    "#print(data.keys())\n",
    "\n",
    "x = data[['Engine speed', 'Engine load', 'Railpressure', 'Air supply', 'Crank angle', 'Intake pressure', 'Back pressure', 'Intake temperature']]\n",
    "y = data[['NOx', 'PM 1', 'CO2', 'PM 2', 'Pressure cylinder']]\n",
    "\n",
    "x_max = x.max()\n",
    "x_min = x.min()\n",
    "y_max = y.max()\n",
    "y_min = y.min()\n",
    "\n",
    "#print(str(y_min) + \"\\n:\\n\" + str(y_max))\n",
    "\n",
    "y_range = y_max - y_min\n",
    "\n",
    "print(y_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datenaufteilung in Training und Test\n",
    "from numpy import double\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.1, random_state=42)\n",
    "\n",
    "\n",
    "# Datenstandardisierung\n",
    "scaler_X = StandardScaler()\n",
    "scaler_y = StandardScaler()\n",
    "\n",
    "# X_train = scaler_X.fit_transform(X_train)\n",
    "# X_test = scaler_X.transform(X_test)\n",
    "\n",
    "# y_train = scaler_y.fit_transform(y_train)\n",
    "# y_test = scaler_y.transform(y_test)\n",
    "\n",
    "x_train = np.array(X_train.values, dtype=float)\n",
    "x_test = np.array(X_train.values, dtype=float)\n",
    "y_test = np.array(y_test.values, dtype=float)\n",
    "y_train = np.array(y_train.values, dtype=float)\n",
    "\n",
    "# Umwandlung in PyTorch Tensors\n",
    "X_train = torch.from_numpy(x_train)\n",
    "X_test = torch.from_numpy(x_test)\n",
    "y_train = torch.from_numpy(y_train)\n",
    "y_test = torch.from_numpy(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.layer1 = nn.Linear(8, 16)\n",
    "        self.layer2 = nn.Linear(16, 12)\n",
    "        self.layer3 = nn.Linear(12, 10)\n",
    "        self.output = nn.Linear(10, 5)\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        print(x.type)\n",
    "        mat = torch.diag(torch.tensor([1, 1, 1, 1, 1, 1, 1, 1])).to(torch.float64)\n",
    "        print(mat.type)\n",
    "        x = torch.matmul(x, mat)\n",
    "        x = self.relu(self.layer1(x))\n",
    "        x = self.relu(self.layer2(x))\n",
    "        x = self.relu(self.layer3(x))\n",
    "        x = self.output(x)\n",
    "        return x\n",
    "\n",
    "model = NeuralNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verlustfunktion und Optimierer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Trainingsparameter\n",
    "num_epochs = 300\n",
    "batch_size = 3\n",
    "\n",
    "# Daten in Batches aufteilen\n",
    "train_dataset = torch.utils.data.TensorDataset(X_train, y_train)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 must have the same dtype, but got Double and Float",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[66], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, (inputs, targets) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_loader):\n\u001b[0;32m      3\u001b[0m         \u001b[38;5;66;03m# Forward-Pass\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m         loss \u001b[38;5;241m=\u001b[39m criterion(outputs, targets)\n\u001b[0;32m      7\u001b[0m         \u001b[38;5;66;03m# Backward-Pass und Optimierung\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[64], line 12\u001b[0m, in \u001b[0;36mNeuralNet.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m     11\u001b[0m     x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmatmul(x, torch\u001b[38;5;241m.\u001b[39mdiag(torch\u001b[38;5;241m.\u001b[39mtensor([\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m]))\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mfloat64))\n\u001b[1;32m---> 12\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     13\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer2(x))\n\u001b[0;32m     14\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer3(x))\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\nn\\modules\\linear.py:116\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 must have the same dtype, but got Double and Float"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    for i, (inputs, targets) in enumerate(train_loader):\n",
    "        # Forward-Pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        \n",
    "        # Backward-Pass und Optimierung\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# Modell speichern (optional)\n",
    "torch.save(model.state_dict(), 'model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[213.38683499   2.92700271  99.85273479   2.51839192  95.81970808]:[165.12383952   3.63098577 104.66582448   7.39466181  99.42012039]\n",
      "[373.58386933   0.73865842  41.63340887 150.46435799  93.4080011 ]:[315.43017611   0.77328927  39.26986336   4.29842533  93.84214037]\n",
      "[147.01234983   2.58613577  63.63875948   4.35376852  79.56792392]:[134.17139995   3.24507671  65.66739663  12.91363239  74.54426619]\n",
      "[ 46.74416278   0.79590238  16.18592546 -23.72326107  54.3879884 ]:[50.60140561  0.53715259 16.30251046  2.32967088 53.86597464]\n",
      "[11.80065251  0.2218374   6.53372202  2.2914528  49.58671435]:[22.09589589  0.19848541  3.68189797  1.95892306 45.77107311]\n",
      "[92.12566554  1.8562298  35.33763786 36.85857762 61.55148618]:[94.23298579  2.83292102 38.50904867 10.53630152 59.95670698]\n",
      "[ 83.04124059   2.65315541  34.65893193 -42.98971699  61.57223513]:[66.86942159  4.09588523 36.29146669 16.28325391 60.4979292 ]\n",
      "[213.60988223   2.54992465  92.62367252 -11.96991153  96.15501912]:[187.19869988   2.89297773  92.99648341   4.85297291 101.07108266]\n",
      "[172.63736229   2.63702404  74.54650348  43.67126264  88.89983029]:[125.64479646   2.20566869  76.37898259   4.49454656  86.9086685 ]\n",
      "[33.34780322  0.47520919 13.01549995 -2.89088629 53.54355872]:[35.58893479  0.47113026 13.47677891  4.47488169 57.43578694]\n",
      "[136.70753499   1.73286414  64.84640347  44.05104162  77.05574957]:[126.57929093   0.52562805  65.46926124   1.17045406  71.75000719]\n",
      "[476.21777776   2.29397801 102.7283531   79.71668873 124.08125646]:[381.61862069   1.92270505  98.68514152   4.47689808 116.51884407]\n"
     ]
    }
   ],
   "source": [
    "model.eval()  # Setzt das Modell in den Evaluationsmodus\n",
    "with torch.no_grad():  # Keine Gradientenberechnung\n",
    "    y_pred = model(X_test)\n",
    "    #test_loss = criterion(y_pred, y_test)\n",
    "    #print(y_test)\n",
    "    \n",
    "    #print(f'Test Loss: {test_loss.item():.4f}')\n",
    "    # y_pred = scaler_y.inverse_transform(y_pred)\n",
    "    # y_test = scaler_y.inverse_transform(y_test)\n",
    "    for pred, test in zip(y_pred, y_test):\n",
    "        print(str(pred) + \":\" + str(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build matrix of elementwise mean squared error\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "matrix = []\n",
    "for pred, test in zip(y_pred, y_test):\n",
    "    data_set_mse = []\n",
    "    for p, t in zip(pred, test):\n",
    "        #print(str(pred) + \":\" + str(test))\n",
    "        mse = mean_squared_error([p], [t])\n",
    "        data_set_mse.append(mse)\n",
    "    #print(data_set_mse)\n",
    "\n",
    "    percentage_to_range = data_set_mse / y_max\n",
    "    matrix.append(percentage_to_range)\n",
    "#print(matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "0.6416120476889968\n",
      "1.6386085155394856\n",
      "0.08691074023497959\n",
      "0.02974677535579845\n",
      "0.054793438092831125\n",
      "0.05560680289239114\n",
      "0.228661600450035\n",
      "0.218461201763019\n",
      "0.6259961473967948\n",
      "0.02223263268190794\n",
      "0.1491603938797818\n",
      "2.5617789498437435\n",
      "Mean:\n",
      "0.5261307704849804\n"
     ]
    }
   ],
   "source": [
    "# check mse per dataset row\n",
    "\n",
    "from statistics import mean \n",
    "\n",
    "mean_for_predicted_dataset = []\n",
    "\n",
    "for predicted_dataset in matrix:\n",
    "    mean_for_predicted_dataset.append(mean(predicted_dataset))\n",
    "\n",
    "print(\"\\n\")\n",
    "for entry in mean_for_predicted_dataset:\n",
    "    print(entry)\n",
    "\n",
    "print(\"Mean:\")\n",
    "print(mean(mean_for_predicted_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1518.7794968111255, 0.4944098757409659, 6.181859571268497, 2976.5326859449583, 15.461706919483072]\n",
      "mse per feature in percentage to value range\n",
      "NOx                  0.002429\n",
      "PM 1                 0.002599\n",
      "CO2                  0.000232\n",
      "PM 2                 0.000098\n",
      "Pressure cylinder    0.000591\n",
      "dtype: Float64\n"
     ]
    }
   ],
   "source": [
    "# Ceck Accuracy among features of test data\n",
    "\n",
    "#print(y_pred.shape)\n",
    "\n",
    "y_pred_t = np.transpose(y_pred)\n",
    "y_test_t = np.transpose(y_test)\n",
    "\n",
    "# print(y_pred_t.shape)\n",
    "# print(y_test_t.shape)\n",
    "featurewise_mean = []\n",
    "for feature_t, feature_p in zip(y_test_t, y_pred_t):\n",
    "    # print(feature_t)\n",
    "    # print(feature_p)\n",
    "    # print(mean_squared_error(feature_t, feature_p))\n",
    "    featurewise_mean.append(mean_squared_error(feature_t, feature_p))\n",
    "\n",
    "print(featurewise_mean)\n",
    "\n",
    "#print(y_range)\n",
    "featurewise_mean_percentage = featurewise_mean / y_max**2\n",
    "print(\"mse per feature in percentage to value range\")\n",
    "print(featurewise_mean_percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "non-broadcastable output operand with shape (5,1) doesn't match the broadcast shape (5,5)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[60], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m testResults \u001b[38;5;241m=\u001b[39m model(x)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mtype\u001b[39m(testResults))\n\u001b[1;32m----> 5\u001b[0m testResults \u001b[38;5;241m=\u001b[39m \u001b[43mscaler_y\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minverse_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtestResults\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(testResults)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m#[125.10746278858385, 0.4371585551795759, 20.70223941458411, 3.4443235692265173, 102.99879114216813]\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\preprocessing\\_data.py:1103\u001b[0m, in \u001b[0;36mStandardScaler.inverse_transform\u001b[1;34m(self, X, copy)\u001b[0m\n\u001b[0;32m   1101\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1102\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwith_std:\n\u001b[1;32m-> 1103\u001b[0m         \u001b[43mX\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale_\u001b[49m\n\u001b[0;32m   1104\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwith_mean:\n\u001b[0;32m   1105\u001b[0m         X \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmean_\n",
      "\u001b[1;31mValueError\u001b[0m: non-broadcastable output operand with shape (5,1) doesn't match the broadcast shape (5,5)"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "x = torch.tensor([16.4712565906533, 37.609734587256995, 900.1427871055062, 228.42045796100746, -8.592515890505748, 1981.8799610478413, 3509.5803914574226, 48.709871706251796])\n",
    "testResults = model(x)\n",
    "print(type(testResults))\n",
    "testResults = scaler_y.inverse_transform(testResults.unsqueeze(0).detach().numpy())\n",
    "print(testResults)\n",
    "#[125.10746278858385, 0.4371585551795759, 20.70223941458411, 3.4443235692265173, 102.99879114216813]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
