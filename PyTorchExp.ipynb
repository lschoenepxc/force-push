{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "# Beispielhafte Daten\n",
    "# X = np.random.rand(100, 13)\n",
    "# y = np.random.rand(100, 5)\n",
    "\n",
    "# Deine echten Daten hier laden\n",
    "X = ... # Dein Input-Datensatz (100, 13)\n",
    "y = ... # Dein Output-Datensatz (100, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOx                  685.846823\n",
      "PM 1                   5.547569\n",
      "CO2                  160.188892\n",
      "PM 2                  15.561156\n",
      "Pressure cylinder    115.101073\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"initial_data.csv\")\n",
    "\n",
    "#print(data)\n",
    "#print(data.keys())\n",
    "\n",
    "x = data[['Engine speed', 'Engine load', 'Railpressure', 'Air supply', 'Crank angle', 'Intake pressure', 'Back pressure', 'Intake temperature']]\n",
    "y = data[['NOx', 'PM 1', 'CO2', 'PM 2', 'Pressure cylinder']]\n",
    "\n",
    "x_max = x.max()\n",
    "x_min = x.min()\n",
    "y_max = y.max()\n",
    "y_min = y.min()\n",
    "\n",
    "#print(str(y_min) + \"\\n:\\n\" + str(y_max))\n",
    "\n",
    "y_range = y_max - y_min\n",
    "\n",
    "print(y_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datenaufteilung in Training und Test\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.1, random_state=42)\n",
    "\n",
    "\n",
    "# Datenstandardisierung\n",
    "scaler_X = StandardScaler()\n",
    "scaler_y = StandardScaler()\n",
    "\n",
    "X_train = scaler_X.fit_transform(X_train)\n",
    "X_test = scaler_X.transform(X_test)\n",
    "\n",
    "y_train = scaler_y.fit_transform(y_train)\n",
    "y_test = scaler_y.transform(y_test)\n",
    "\n",
    "\n",
    "\n",
    "# Umwandlung in PyTorch Tensors\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test, dtype=torch.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.layer1 = nn.Linear(8, 16)\n",
    "        self.layer2 = nn.Linear(16, 12)\n",
    "        self.layer3 = nn.Linear(12, 10)\n",
    "        self.output = nn.Linear(10, 5)\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = torch.matmul(x, torch.diag(torch.tensor([1, 1, 1, 1, 1, 1, 1, 1])).to(torch.float32))\n",
    "        x = self.relu(self.layer1(x))\n",
    "        x = self.relu(self.layer2(x))\n",
    "        x = self.relu(self.layer3(x))\n",
    "        x = self.output(x)\n",
    "        return x\n",
    "\n",
    "model = NeuralNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verlustfunktion und Optimierer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Trainingsparameter\n",
    "num_epochs = 300\n",
    "batch_size = 3\n",
    "\n",
    "# Daten in Batches aufteilen\n",
    "train_dataset = torch.utils.data.TensorDataset(X_train, y_train)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/300], Loss: 0.1790\n",
      "Epoch [20/300], Loss: 0.2265\n",
      "Epoch [30/300], Loss: 0.2192\n",
      "Epoch [40/300], Loss: 0.0476\n",
      "Epoch [50/300], Loss: 0.0921\n",
      "Epoch [60/300], Loss: 0.1676\n",
      "Epoch [70/300], Loss: 0.0619\n",
      "Epoch [80/300], Loss: 0.0525\n",
      "Epoch [90/300], Loss: 0.0983\n",
      "Epoch [100/300], Loss: 0.2203\n",
      "Epoch [110/300], Loss: 0.1992\n",
      "Epoch [120/300], Loss: 0.1003\n",
      "Epoch [130/300], Loss: 0.0352\n",
      "Epoch [140/300], Loss: 0.0613\n",
      "Epoch [150/300], Loss: 0.1012\n",
      "Epoch [160/300], Loss: 0.0479\n",
      "Epoch [170/300], Loss: 0.0170\n",
      "Epoch [180/300], Loss: 0.0750\n",
      "Epoch [190/300], Loss: 0.0296\n",
      "Epoch [200/300], Loss: 0.0792\n",
      "Epoch [210/300], Loss: 0.2629\n",
      "Epoch [220/300], Loss: 0.0520\n",
      "Epoch [230/300], Loss: 0.0382\n",
      "Epoch [240/300], Loss: 0.0336\n",
      "Epoch [250/300], Loss: 0.3545\n",
      "Epoch [260/300], Loss: 0.0783\n",
      "Epoch [270/300], Loss: 0.0210\n",
      "Epoch [280/300], Loss: 0.0760\n",
      "Epoch [290/300], Loss: 0.0418\n",
      "Epoch [300/300], Loss: 0.0369\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    for i, (inputs, targets) in enumerate(train_loader):\n",
    "        # Forward-Pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        \n",
    "        # Backward-Pass und Optimierung\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# Modell speichern (optional)\n",
    "torch.save(model.state_dict(), 'model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50.16998742  0.29901642 20.39050843  1.45022837 55.83422986]:[45.11063706  0.37043239 13.33908759  1.34438471 50.75279046]\n",
      "[137.13124414   3.12919883  64.87213747  10.57881731  71.97648359]:[144.31417996   3.2442979   63.07336518   9.38207516  71.47676054]\n",
      "[67.49732175  2.06018466 40.57895232  8.11364189 61.44214902]:[66.86942417  4.09588526 36.29146793 16.28325513 60.49792953]\n",
      "[62.83617101  2.34888773 36.50451453 10.30166379 59.62885575]:[94.23299035  2.83292106 38.50904745 10.53630092 59.95670593]\n",
      "[43.37890152  1.08424429 21.93206025  5.70665367 54.94434136]:[41.90699086  0.76024322 22.40993205  4.24715129 54.66871374]\n",
      "[90.58328518  2.75059232 45.51759878 11.34183166 64.36504142]:[84.29989805  3.41757813 48.34347086 14.36933964 66.03415315]\n",
      "[565.56219963   1.1377963   76.43880999   2.83326371 107.19086693]:[465.21158656   0.99647182  76.01429871   2.44630606 107.39016145]\n",
      "[205.88386307   3.22973889  98.91874429   5.78571763 101.63465466]:[165.12383548   3.63098576 104.66582744   7.39466323  99.42011942]\n",
      "[10.56506365  0.12638085  1.87212241  2.85875864 49.68180315]:[22.09589639  0.19848545  3.68189957  1.95892246 45.7710704 ]\n",
      "[ 4.54102621 -0.21107524 -4.82201349  1.96768165 47.32059796]:[17.97783801  0.15113867  2.89162952  1.69033535 44.94630108]\n"
     ]
    }
   ],
   "source": [
    "model.eval()  # Setzt das Modell in den Evaluationsmodus\n",
    "with torch.no_grad():  # Keine Gradientenberechnung\n",
    "    y_pred = model(X_test)\n",
    "    #test_loss = criterion(y_pred, y_test)\n",
    "    #print(y_test)\n",
    "    \n",
    "    #print(f'Test Loss: {test_loss.item():.4f}')\n",
    "    y_pred = scaler_y.inverse_transform(y_pred)\n",
    "    y_test = scaler_y.inverse_transform(y_test)\n",
    "    for pred, test in zip(y_pred, y_test):\n",
    "        print(str(pred) + \":\" + str(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build matrix of elementwise mean squared error\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "matrix = []\n",
    "for pred, test in zip(y_pred, y_test):\n",
    "    data_set_mse = []\n",
    "    for p, t in zip(pred, test):\n",
    "        #print(str(pred) + \":\" + str(test))\n",
    "        mse = mean_squared_error([p], [t])\n",
    "        data_set_mse.append(mse)\n",
    "    #print(data_set_mse)\n",
    "\n",
    "    percentage_to_range = data_set_mse / y_max\n",
    "    matrix.append(percentage_to_range)\n",
    "#print(matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "0.10083614281642696\n",
      "0.03699725601479078\n",
      "0.9889789518378173\n",
      "0.29407614353646955\n",
      "0.03083851891390508\n",
      "0.15268627733902634\n",
      "2.864388656409348\n",
      "0.556181512307474\n",
      "0.07103829130675303\n",
      "0.1368690631075893\n",
      "Mean:\n",
      "0.52328908135896\n"
     ]
    }
   ],
   "source": [
    "# check mse per dataset row\n",
    "\n",
    "from statistics import mean \n",
    "\n",
    "mean_for_predicted_dataset = []\n",
    "\n",
    "for predicted_dataset in matrix:\n",
    "    mean_for_predicted_dataset.append(mean(predicted_dataset))\n",
    "\n",
    "print(\"\\n\")\n",
    "for entry in mean_for_predicted_dataset:\n",
    "    print(entry)\n",
    "\n",
    "print(\"Mean:\")\n",
    "print(mean(mean_for_predicted_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1315.0126996006234, 0.5263929657956787, 17.955746335336666, 8.31620497108278, 5.580669124125534]\n",
      "mse per feature in percentage to value range\n",
      "NOx                  0.002655\n",
      "PM 1                 0.016209\n",
      "CO2                  0.000675\n",
      "PM 2                 0.031365\n",
      "Pressure cylinder    0.000218\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Ceck Accuracy among features of test data\n",
    "\n",
    "#print(y_pred.shape)\n",
    "\n",
    "y_pred_t = np.transpose(y_pred)\n",
    "y_test_t = np.transpose(y_test)\n",
    "\n",
    "# print(y_pred_t.shape)\n",
    "# print(y_test_t.shape)\n",
    "featurewise_mean = []\n",
    "for feature_t, feature_p in zip(y_test_t, y_pred_t):\n",
    "    # print(feature_t)\n",
    "    # print(feature_p)\n",
    "    # print(mean_squared_error(feature_t, feature_p))\n",
    "    featurewise_mean.append(mean_squared_error(feature_t, feature_p))\n",
    "\n",
    "print(featurewise_mean)\n",
    "\n",
    "#print(y_range)\n",
    "featurewise_mean_percentage = featurewise_mean / y_max**2\n",
    "print(\"mse per feature in percentage to value range\")\n",
    "print(featurewise_mean_percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 497.9112,  680.5526,  845.7199,  -16.8309, 1187.9828],\n",
      "       grad_fn=<ViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([16.4712565906533, 37.609734587256995, 900.1427871055062, 228.42045796100746, -8.592515890505748, 1981.8799610478413, 3509.5803914574226, 48.709871706251796])\n",
    "testResults = model(x)\n",
    "print(testResults)\n",
    "#[125.10746278858385, 0.4371585551795759, 20.70223941458411, 3.4443235692265173, 102.99879114216813]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
