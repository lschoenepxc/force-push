{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "# Beispielhafte Daten\n",
    "# X = np.random.rand(100, 13)\n",
    "# y = np.random.rand(100, 5)\n",
    "\n",
    "# Deine echten Daten hier laden\n",
    "X = ... # Dein Input-Datensatz (100, 13)\n",
    "y = ... # Dein Output-Datensatz (100, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import re\n",
    "\n",
    "def read_csv_file(file_path):\n",
    "    # Initialisiere eine leere Liste, um die bereinigten Daten zu speichern\n",
    "    cleaned_data = []\n",
    "\n",
    "    # Lese die CSV-Datei\n",
    "    with open(file_path, 'r') as csvfile:\n",
    "        reader = csv.reader(csvfile, delimiter=';')  # Annahme: Semikolon als Trennzeichen\n",
    "        for row in reader:\n",
    "            # Verbinde die Zeilenelemente mit einem Komma, um das Trennzeichen zu vereinheitlichen\n",
    "            unified_row = ','.join(row)\n",
    "            # Ersetze mehrere aufeinander folgende Kommas durch ein einzelnes Komma\n",
    "            unified_row = re.sub(r',+', ',', unified_row)\n",
    "            # Teile die vereinheitlichte Zeile nach dem Komma auf\n",
    "            split_row = unified_row.split(',')\n",
    "            # Entferne die ersten zwei Parameter\n",
    "            cleaned_row = split_row[1:]\n",
    "            # FÃ¼ge die bereinigte Zeile der Liste hinzu\n",
    "            cleaned_data.append(cleaned_row)\n",
    "\n",
    "    return cleaned_data\n",
    "\n",
    "# Beispiel: Daten aus \"input.csv\" einlesen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Engine speed', 'Engine load', 'Railpressure', 'Air supply',\n",
      "       'Crank angle', 'Intake pressure', 'Back pressure', 'Intake temperature',\n",
      "       'NOx', 'PM 1', 'CO2', 'PM 2', 'Pressure cylinder', 'costs'],\n",
      "      dtype='object')\n",
      "    index  Engine speed  Engine load  Railpressure   Air supply  Crank angle  \\\n",
      "0     0.0         700.0         7.33    500.899994    78.375298         1.91   \n",
      "1     1.0         700.0        25.85    577.599976   118.067299         0.94   \n",
      "2     2.0         700.0    46.669998    615.799988   144.355698         2.86   \n",
      "3     3.0         700.0    69.550003    778.299988   174.177902         2.22   \n",
      "4     4.0         700.0    94.330002    900.099976   213.314804        -1.72   \n",
      "..    ...           ...          ...           ...          ...          ...   \n",
      "95   95.0        2100.0   124.970001   2500.100098  1010.203125         4.27   \n",
      "96   96.0        2200.0         12.6   2294.600098   321.264893          5.7   \n",
      "97   97.0        2200.0    31.969999   2407.800049   360.026703         4.44   \n",
      "98   98.0        2200.0    53.830002   2499.199951   533.573425         1.76   \n",
      "99   99.0        2200.0    74.830002        2500.0   700.009521         3.02   \n",
      "\n",
      "    Intake pressure  Back pressure  Intake temperature         NOx      PM 1  \\\n",
      "0             967.5    1027.300049                65.5   17.977839  0.151139   \n",
      "1       1017.599976    1063.800049           53.400002   30.613787  0.421432   \n",
      "2       1086.699951    1156.199951           47.900002  109.199806  0.767395   \n",
      "3       1171.099976    1215.099976           42.700001  186.406723  0.658505   \n",
      "4       1313.300049    1305.900024           38.299999  315.430176  0.773289   \n",
      "..              ...            ...                 ...         ...       ...   \n",
      "95           3036.0    3326.600098           80.599998  278.449036   3.48829   \n",
      "96           1084.5    1251.599976                68.0   68.305489  0.239003   \n",
      "97      1210.400024         1407.5           68.099998   59.023117   0.73086   \n",
      "98      1541.099976         1684.0           63.799999  126.579292  0.525628   \n",
      "99      1989.699951    2139.800049                68.0   157.50798  3.878053   \n",
      "\n",
      "           CO2      PM 2  Pressure cylinder  \n",
      "0     2.891628  1.690336          44.946301  \n",
      "1    10.976312  4.617809          55.885777  \n",
      "2    18.844496  5.139177          73.029762  \n",
      "3    27.739765  4.104144          86.322105  \n",
      "4    39.269863  4.298426           93.84214  \n",
      "..         ...       ...                ...  \n",
      "95  146.110062  5.469055         147.986145  \n",
      "96   14.550721  0.732065          55.088165  \n",
      "97    40.95097  2.564499          60.120396  \n",
      "98   65.469261  1.170453          71.750008  \n",
      "99   86.525482  4.955919          99.713654  \n",
      "\n",
      "[100 rows x 14 columns]\n",
      "100\n",
      "100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\boeke\\AppData\\Local\\Temp\\ipykernel_17072\\3903568553.py:8: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  data = pd.concat([data, queried_data.iloc[:, :13]], axis=0)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"initial_data.csv\")\n",
    "cleaned_data = read_csv_file(\"querys_ForcePush.csv\")\n",
    "df_queried = pd.DataFrame(cleaned_data[1:], columns=cleaned_data[0])\n",
    "def add_data(data, queried_data):\n",
    "    # add queried data (without cost) to initial data\n",
    "    print(queried_data.keys())\n",
    "    queried_data = queried_data[queried_data['costs'] == 1]\n",
    "    data = pd.concat([data, queried_data.iloc[:, :13]], axis=0)\n",
    "\n",
    "    # data = data.append(queried_data, ignore_index=True)\n",
    "    return data\n",
    "\n",
    "data = add_data(data, df_queried)\n",
    "data = data.reset_index().astype('Float32')\n",
    "\n",
    "print(data)\n",
    "\n",
    "#print(data)\n",
    "#print(data.keys())\n",
    "\n",
    "x = data[['Engine speed', 'Engine load', 'Railpressure', 'Air supply', 'Crank angle', 'Intake pressure', 'Back pressure', 'Intake temperature']]\n",
    "y = data[['NOx', 'PM 1', 'CO2', 'PM 2', 'Pressure cylinder']]\n",
    "\n",
    "print(len(x))\n",
    "print(len(y))\n",
    "\n",
    "x_max = x.max()\n",
    "x_min = x.min()\n",
    "y_max = y.max()\n",
    "y_min = y.min()\n",
    "y_var = y.var()\n",
    "\n",
    "#print(str(y_min) + \"\\n:\\n\" + str(y_max))\n",
    "\n",
    "y_range = y_max - y_min\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "# Datenaufteilung in Training und Test\n",
    "\n",
    "\n",
    "print(len(x))\n",
    "print(len(y))\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.1, random_state=42)\n",
    "\n",
    "\n",
    "# Datenstandardisierung\n",
    "scaler_X = StandardScaler()\n",
    "scaler_y = StandardScaler()\n",
    "\n",
    "#X_train = scaler_X.fit_transform(X_train)\n",
    "#X_test = scaler_X.transform(X_test)\n",
    "\n",
    "#y_train = scaler_y.fit_transform(y_train)\n",
    "#y_test = scaler_y.transform(y_test)\n",
    "\n",
    "\n",
    "pls2 = PLSRegression(n_components=3)\n",
    "pls2.fit(X_train, y_train)\n",
    "\n",
    "test_results = pls2.predict(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 5)\n",
      "(10, 5)\n",
      "mean_squared_error:\n",
      "2946.870414\n",
      "1.696068  \n",
      "29.100488 \n",
      "25.930863 \n",
      "18.317407 \n",
      "mean_absolute_percentage_error:\n",
      "72.632742 \n",
      "78.835890 \n",
      "58.856016 \n",
      "77.323406 \n",
      "5.158597  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_percentage_error, mean_squared_error\n",
    "\n",
    "\n",
    "featurewise_mse = []\n",
    "featurewise_map = []\n",
    "print(test_results.shape)\n",
    "print(y_test.shape)\n",
    "y_test = np.transpose(y_test)\n",
    "test_results = np.transpose(test_results)\n",
    "for feature_t, feature_p in zip(test_results, y_test.values):\n",
    "    # print(feature_t)\n",
    "    # print(feature_p)\n",
    "    # print(mean_squared_error(feature_t, feature_p))\n",
    "    featurewise_map.append(mean_absolute_percentage_error(feature_t, feature_p))\n",
    "    featurewise_mse.append(mean_squared_error(feature_t, feature_p))\n",
    "\n",
    "featurewise_mse = np.array(featurewise_mse)\n",
    "\n",
    "featurewise_map = np.array(featurewise_map)\n",
    "#print(featurewise_mean)\n",
    "# print(y_max.shape)\n",
    "# print(featurewise_mean.shape)\n",
    "# #print(y_range)\n",
    "# featurewise_mean_percentage = featurewise_mean / y_max**2\n",
    "# featurewise_mean_divided_by_variance = featurewise_mean / y_var\n",
    "print(\"mean_squared_error:\")\n",
    "for mean in featurewise_mse:\n",
    "    print('{:<10f}'.format(mean))\n",
    "print(\"mean_absolute_percentage_error:\")\n",
    "for mean in featurewise_map:\n",
    "    print('{:<10f}'.format(mean*100))\n",
    "\n",
    "# print(\"mse per feature in percentage to value range\")\n",
    "# print(featurewise_mean_percentage)\n",
    "# print(\"featurewise_mean_divided_by_variance:\")\n",
    "# print(featurewise_mean_divided_by_variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[263.1563737387438, 2.2356318186765023, 83.79336361410725, 4.709627978763616, 106.5400573624858]\n",
      "[88.87191484400569, 0.7323163829270714, 25.857270103130983, 1.69463046712027, 21.237226518494598]\n",
      "[170.29038274765014, 1.9017370684444905, 59.82909906625748, 5.4507354098558425, 82.80317947387695]\n",
      "[133.46353806052107, 1.29944648318814, 40.135816557622924, 3.0441017736734306, 28.307689588618114]\n",
      "\n",
      "Quotienten von mean und std:\n",
      "\n",
      "[0.64710719 0.8506486  0.71400761 1.15736008 0.77720232]\n",
      "[1.50175157 1.77443317 1.55220626 1.79632187 1.3329278 ]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "submission_data = pd.read_csv(\"submission.csv\")\n",
    "\n",
    "\n",
    "#print(submission_data)\n",
    "#print(submission_data.keys())\n",
    "\n",
    "submission_keys = ['Speed', 'Load', 'Railpressure', 'Air', 'Angle', 'Pressure1','Pressure2', 'Temperature']\n",
    "model_keys = ['Engine speed', 'Engine load', 'Railpressure', 'Air supply', 'Crank angle', 'Intake pressure', 'Back pressure', 'Intake temperature']\n",
    "\n",
    "for sub_key, mod_key in zip(submission_keys, model_keys):\n",
    "    submission_data = submission_data.rename(columns={sub_key:mod_key})\n",
    "\n",
    "\n",
    "\n",
    "# input = input.reshape((1,8))\n",
    "submission_result = pls2.predict(submission_data)\n",
    "\n",
    "\n",
    "submission_result = np.transpose(submission_result)\n",
    "submission_std = []\n",
    "submission_mean = []\n",
    "#print(submission_result)\n",
    "for feature in submission_result:\n",
    "    submission_std.append(feature.std())\n",
    "    submission_mean.append(feature.mean())\n",
    "\n",
    "print(submission_mean)\n",
    "print(submission_std)\n",
    "\n",
    "y_std = []\n",
    "y_mean = []\n",
    "#print(y)\n",
    "y_t = np.transpose(np.array(y))\n",
    "\n",
    "for feature in y_t:\n",
    "    #print(feature)\n",
    "    y_std.append(feature.std())\n",
    "    y_mean.append(feature.mean())\n",
    "\n",
    "\n",
    "print(y_mean)\n",
    "print(y_std)\n",
    "\n",
    "q_mean = np.divide(y_mean, submission_mean)\n",
    "q_std = np.divide(y_std, submission_std)\n",
    "\n",
    "print(\"\\nQuotienten von mean und std:\\n\")\n",
    "print(q_mean)\n",
    "print(q_std)\n",
    "\n",
    "# print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
