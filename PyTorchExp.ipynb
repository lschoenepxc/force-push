{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "# Beispielhafte Daten\n",
    "# X = np.random.rand(100, 13)\n",
    "# y = np.random.rand(100, 5)\n",
    "\n",
    "# Deine echten Daten hier laden\n",
    "X = ... # Dein Input-Datensatz (100, 13)\n",
    "y = ... # Dein Output-Datensatz (100, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Engine speed', 'Engine load', 'Railpressure', 'Air supply',\n",
      "       'Crank angle', 'Intake pressure', 'Back pressure', 'Intake temperature',\n",
      "       'NOx', 'PM 1', 'CO2', 'PM 2', 'Pressure cylinder'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"initial_data.csv\")\n",
    "\n",
    "print(data)\n",
    "#print(data.keys())\n",
    "\n",
    "x = data[['Engine speed', 'Engine load', 'Railpressure', 'Air supply', 'Crank angle', 'Intake pressure', 'Back pressure', 'Intake temperature']]\n",
    "y = data[['NOx', 'PM 1', 'CO2', 'PM 2', 'Pressure cylinder']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datenaufteilung in Training und Test\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Datenstandardisierung\n",
    "scaler_X = StandardScaler()\n",
    "scaler_y = StandardScaler()\n",
    "\n",
    "X_train = scaler_X.fit_transform(X_train)\n",
    "X_test = scaler_X.transform(X_test)\n",
    "\n",
    "y_train = scaler_y.fit_transform(y_train)\n",
    "y_test = scaler_y.transform(y_test)\n",
    "\n",
    "# Umwandlung in PyTorch Tensors\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.layer1 = nn.Linear(8, 16)\n",
    "        self.layer2 = nn.Linear(16, 16)\n",
    "        self.layer3 = nn.Linear(16, 10)\n",
    "        self.output = nn.Linear(10, 5)\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.layer1(x))\n",
    "        x = self.relu(self.layer2(x))\n",
    "        x = self.relu(self.layer3(x))\n",
    "        x = self.output(x)\n",
    "        return x\n",
    "\n",
    "model = NeuralNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verlustfunktion und Optimierer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Trainingsparameter\n",
    "num_epochs = 150\n",
    "batch_size = 10\n",
    "\n",
    "# Daten in Batches aufteilen\n",
    "train_dataset = torch.utils.data.TensorDataset(X_train, y_train)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/150], Loss: 0.9082\n",
      "Epoch [20/150], Loss: 0.8704\n",
      "Epoch [30/150], Loss: 0.2025\n",
      "Epoch [40/150], Loss: 0.0791\n",
      "Epoch [50/150], Loss: 0.3182\n",
      "Epoch [60/150], Loss: 0.1381\n",
      "Epoch [70/150], Loss: 0.1965\n",
      "Epoch [80/150], Loss: 0.3453\n",
      "Epoch [90/150], Loss: 0.0730\n",
      "Epoch [100/150], Loss: 0.1032\n",
      "Epoch [110/150], Loss: 0.0966\n",
      "Epoch [120/150], Loss: 0.0922\n",
      "Epoch [130/150], Loss: 0.1560\n",
      "Epoch [140/150], Loss: 0.1594\n",
      "Epoch [150/150], Loss: 0.1127\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    for i, (inputs, targets) in enumerate(train_loader):\n",
    "        # Forward-Pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        \n",
    "        # Backward-Pass und Optimierung\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# Modell speichern (optional)\n",
    "torch.save(model.state_dict(), 'model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.3132\n",
      "tensor([[-1.1002, -0.9322, -1.0134, -0.7805, -1.0543],\n",
      "        [-0.4275,  0.7038, -0.0429,  1.6560, -0.4129],\n",
      "        [-0.8314, -0.1408, -0.5709,  0.3913, -0.7900],\n",
      "        [-0.8045,  0.2496, -0.5947,  1.4952, -0.8004],\n",
      "        [-1.1009, -0.6918, -1.0726, -0.0335, -1.0800],\n",
      "        [-0.6690,  0.6462, -0.3513,  2.0625, -0.6538],\n",
      "        [ 2.5275, -0.7408,  0.3512, -1.0158,  0.9423],\n",
      "        [-0.0382,  0.8642,  0.8987,  0.1424,  0.6666],\n",
      "        [-1.1954, -1.4205, -1.4781, -0.7998, -1.2655],\n",
      "        [-1.3724, -1.7147, -1.6702, -1.1781, -1.4329],\n",
      "        [-0.9966, -0.5455, -1.1096,  0.6052, -1.0361],\n",
      "        [-1.3370, -1.4063, -1.4750, -1.0397, -1.3209],\n",
      "        [ 0.1123,  0.9088,  0.9820,  0.1119,  0.8003],\n",
      "        [-0.4888,  0.6195, -0.2350,  1.8731, -0.5082],\n",
      "        [-1.0249, -0.9254, -0.8964, -0.9284, -0.9786],\n",
      "        [ 1.3995, -1.1178, -0.5982, -0.4100,  0.1069],\n",
      "        [-1.0686, -0.8506, -0.9923, -0.6114, -1.0289],\n",
      "        [-0.9441, -0.6459, -0.7890, -0.4502, -0.8980],\n",
      "        [-0.6595, -0.5428, -1.0189,  0.6922, -0.8456],\n",
      "        [-1.0802, -0.5373, -1.0876,  0.4508, -1.0799]])\n"
     ]
    }
   ],
   "source": [
    "model.eval()  # Setzt das Modell in den Evaluationsmodus\n",
    "with torch.no_grad():  # Keine Gradientenberechnung\n",
    "    y_pred = model(X_test)\n",
    "    test_loss = criterion(y_pred, y_test)\n",
    "    print(f'Test Loss: {test_loss.item():.4f}')\n",
    "    print(y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
